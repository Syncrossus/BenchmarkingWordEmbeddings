{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating text8 model\n",
    "#sentences = word2vec.Text8Corpus(\"~/Documents/ScienceDesDonnees/word2vec/text8\")\n",
    "model = word2vec.Word2Vec(sentences, size=300, window=12, min_count=25, workers=3, sg=1, negative=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read function\n",
    "import pickle\n",
    "def read(file):\n",
    "    with open(file, 'rb') as fichier:\n",
    "        mon_depickler = pickle.Unpickler(fichier)\n",
    "        d_recupere = mon_depickler.load()\n",
    "        return d_recupere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading text8 model\n",
    "model = read('modeltext8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62197202"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity\n",
    "w1 = 'car'\n",
    "w2 = 'automobile'\n",
    "(model.wv[w1].dot(model.wv[w2]))/(np.linalg.norm(model.wv[w1])*np.linalg.norm(model.wv[w2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38240113095977313"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity?\n",
    "model.wv.similarity(w1, w2)\n",
    "# Yes, = relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3201885"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# euclidean distance\n",
    "np.linalg.norm(model.wv[w1]-model.wv[w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming text8\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "stemmer = LancasterStemmer()\n",
    "sentences = word2vec.Text8Corpus(\"text8\")\n",
    "sentences = [[stemmer.stem(word) for word in sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# viewing text8\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# levenshtein distance\n",
    "def levenshtein(l1, l2):\n",
    "    m = np.zeros(shape=(len(l1),len(l2)))\n",
    "    m[0,:] = range(0,len(l2))\n",
    "    m[:,0] = range(0,len(l1))\n",
    "    for i in range(1,len(l1)):\n",
    "        for j in range(1,len(l2)):\n",
    "            cost = 0\n",
    "            if l1[i]!=l2[j]:\n",
    "                cost = 1\n",
    "            m[i, j] = min(m[i-1, j] + cost, m[i, j-1] + cost, m[i-1, j-1] + cost)\n",
    "    return m[len(l1)-1, len(l2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some imports\n",
    "import csv\n",
    "import numpy as np\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading human judgement datasets\n",
    "with open(WORDSIM[0], 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=WORDSIM[1])\n",
    "    # Concaténation de trois colonnes en un tuple de mots et un score\n",
    "    np.matrix([[(i[0], i[1]), float(i[2])] for i in reader])\n",
    "\n",
    "with open(MC_CSV[0], 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=MC_CSV[1])\n",
    "    # Concaténation de trois colonnes en un tuple de mots et un score\n",
    "    np.matrix([[(i[0], i[1]), float(i[2])] for i in reader if any(i)])\n",
    "\n",
    "with open(MTURK[0], 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=MTURK[1])\n",
    "    # Concaténation de trois colonnes en un tuple de mots et un score\n",
    "    np.matrix([[(i[0], i[1]), float(i[2])] for i in reader])\n",
    "\n",
    "with open(REL122[0], 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=REL122[1])\n",
    "    # Concaténation de trois colonnes en un tuple de mots et un score\n",
    "    np.matrix([[(i[1], i[2]), float(i[0])] for i in reader])\n",
    "\n",
    "with open(RG[0], 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=RG[1])\n",
    "    # Concaténation de trois colonnes en un tuple de mots et un score\n",
    "    np.matrix([[(i[0], i[1]), float(i[2])] for i in reader if any(i)])\n",
    "\n",
    "with open(SIMLEX, 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter='\\t')\n",
    "    next(reader)\n",
    "    np.matrix([[(i[0], i[1]), float(i[3])] for i in reader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-af3d3b2b16ca>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-af3d3b2b16ca>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print(np.matrix([[(i[2], i[3]), float(i[0])] for i in reader])\u001b[0m\n\u001b[1;37m                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with open(UMNSRS_REL, 'rt')as fichier:\n",
    "    reader = csv.reader(fichier, delimiter=',')\n",
    "    print(np.matrix([[(i[2], i[3]), float(i[0])] for i in reader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.68876959269881133, 5.134430017190562e-48),\n",
       " SpearmanrResult(correlation=0.725846641469719, pvalue=1.4277253210739351e-55),\n",
       " 5.94900849858357)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_pairs(pairs=\"C:/Users/Syncrossus/Documents/GitHub/BenchmarkingWordEmbeddings/wordsim.csv\",delimiter=';',case_insensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"C:/Users/Syncrossus/Documents/GitHub/BenchmarkingWordEmbeddings/datasets_human_judgements/\"\n",
    "prefix2=\"C:/Users/Syncrossus/Documents/GitHub/BenchmarkingWordEmbeddings/datasets_human_judgements/\"\n",
    "liste=[prefix+'UMNSRS_relatedness.csv',prefix+'UMNSRS_similarity.csv']\n",
    "listeCopie = [prefix2+'UMNSRS_relatedness2.csv',prefix2+'UMNSRS_similarity2.csv']\n",
    "for j in range(len(liste)):\n",
    "    with open(liste[j] , 'rt') as fichier:\n",
    "        reader = csv.reader(fichier, delimiter=',')\n",
    "        a =[[i[2] ,i[3],i[0]] for i in reader]\n",
    "    with open(listeCopie[j], 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
